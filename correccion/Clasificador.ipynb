{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Clasificador naive bayes\n",
    "Lo primero que tenemos que hacer es cargar nuestro archivo de datos. Los datos están en formato CSV sin una línea de encabezado ni ninguna comilla. Podemos abrir el archivo con la función de abrir y leer las líneas de datos usando la función de lector en el módulo csv.\n",
    "\n",
    "También debemos convertir los atributos que se cargaron como cadenas en números para que podamos trabajar con ellos. A continuación se muestra la función loadCsv () para cargar el conjunto de datos de los indios Pima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acerca de Naive Bayes\n",
    "\n",
    "El algoritmo Naive Bayes es un método intuitivo que utiliza las probabilidades de cada atributo que pertenece a cada clase para hacer una predicción. Es el enfoque de aprendizaje supervisado que se le ocurriría si quisiera modelar un problema de modelado predictivo de forma probabilística.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import random\n",
    "def loadCsv():\n",
    "\tlines = csv.reader(open(r'C:\\Users\\Usuario\\Documents\\anaconda\\correccion\\pima-indians-diabetes.csv'))\n",
    "\tdataset = list(lines)\n",
    "\tfor i in range(len(dataset)):\n",
    "\t\tdataset[i] = [float(x) for x in dataset[i]]\n",
    "\treturn dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se muestra la función splitDataset () que dividirá un conjunto de datos determinado en una proporción de división determinada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitDataset(dataset, splitRatio):\n",
    "\ttrainSize = int(len(dataset) * splitRatio)\n",
    "\ttrainSet = []\n",
    "\tcopy = list(dataset)\n",
    "\twhile len(trainSet) < trainSize:\n",
    "\t\tindex = random.randrange(len(copy))\n",
    "\t\ttrainSet.append(copy.pop(index))\n",
    "\treturn [trainSet, copy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función asume que el último atributo (-1) es el valor de la clase. La función devuelve un mapa de valores de clase a listas de instancias de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def separateByClass(dataset):\n",
    "\tseparated = {}\n",
    "\tfor i in range(len(dataset)):\n",
    "\t\tvector = dataset[i]\n",
    "\t\tif (vector[-1] not in separated):\n",
    "\t\t\tseparated[vector[-1]] = []\n",
    "\t\tseparated[vector[-1]].append(vector)\n",
    "\treturn separated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular la media\n",
    "Calcular la media de cada atributo para un valor de clase. La media es la tendencia central media o central de los datos, y la usaremos como la mitad de nuestra distribución gaussiana al calcular las probabilidades.\n",
    "\n",
    "También debemos calcular la desviación estándar de cada atributo para un valor de clase. La desviación estándar describe la variación de la dispersión de los datos, y la usaremos para caracterizar la dispersión esperada de cada atributo en nuestra distribución gaussiana al calcular las probabilidades.\n",
    "\n",
    "La desviación estándar se calcula como la raíz cuadrada de la varianza. La varianza se calcula como el promedio de las diferencias al cuadrado para cada valor de atributo de la media. Tenga en cuenta que estamos utilizando el método N-1, que resta 1 del número de valores de atributo al calcular la varianza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "\treturn sum(numbers)/float(len(numbers))\n",
    " \n",
    "def stdev(numbers):\n",
    "\tavg = mean(numbers)\n",
    "\tvariance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
    "\treturn math.sqrt(variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumir conjunto de datos\n",
    "Ahora tenemos las herramientas para resumir un conjunto de datos. Para una lista dada de instancias (para un valor de clase) podemos calcular la media y la desviación estándar para cada atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summarize(dataset):\n",
    "\tsummaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
    "\tdel summaries[-1]\n",
    "\treturn summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumir atributos por clase\n",
    "Podemos juntarlo todo separando primero nuestro conjunto de datos de entrenamiento en instancias agrupadas por clase. Luego calcula los resúmenes para cada atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summarizeByClass(dataset):\n",
    "\tseparated = separateByClass(dataset)\n",
    "\tsummaries = {}\n",
    "\tfor classValue, instances in separated.items():\n",
    "\t\tsummaries[classValue] = summarize(instances)\n",
    "\treturn summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacer predicción\n",
    "Ahora estamos listos para hacer predicciones utilizando los resúmenes preparados a partir de nuestros datos de capacitación.\n",
    "### Calcular la función de densidad de probabilidad gaussiana\n",
    "Podemos usar una función gaussiana para estimar la probabilidad de un valor de atributo dado, dada la media conocida y la desviación estándar para el atributo estimado a partir de los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateProbability(x, mean, stdev):\n",
    "\texponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "\treturn (1 / (math.sqrt(2*math.pi) * stdev)) * exponent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular probabilidades de clase\n",
    "Ahora que podemos calcular la probabilidad de que un atributo pertenezca a una clase, podemos combinar las probabilidades de todos los valores de atributo para una instancia de datos y obtener una probabilidad de que toda la instancia de datos pertenezca a la clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateClassProbabilities(summaries, inputVector):\n",
    "\tprobabilities = {}\n",
    "\tfor classValue, classSummaries in summaries.items():\n",
    "\t\tprobabilities[classValue] = 1\n",
    "\t\tfor i in range(len(classSummaries)):\n",
    "\t\t\tmean, stdev = classSummaries[i]\n",
    "\t\t\tx = inputVector[i]\n",
    "\t\t\tprobabilities[classValue] *= calculateProbability(x, mean, stdev)\n",
    "\treturn probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haz una predicción\n",
    "Ahora que podemos calcular la probabilidad de que una instancia de datos pertenezca a cada valor de clase, podemos buscar la mayor probabilidad y devolver la clase asociada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(summaries, inputVector):\n",
    "\tprobabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "\tbestLabel, bestProb = None, -1\n",
    "\tfor classValue, probability in probabilities.items():\n",
    "\t\tif bestLabel is None or probability > bestProb:\n",
    "\t\t\tbestProb = probability\n",
    "\t\t\tbestLabel = classValue\n",
    "\treturn bestLabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacer predicciones\n",
    "Finalmente, podemos estimar la precisión del modelo haciendo predicciones para cada instancia de datos en nuestro conjunto de datos de prueba. Los getPredictions () van a hacer esto y devolver una lista de predicciones para cada instancia de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPredictions(summaries, testSet):\n",
    "\tpredictions = []\n",
    "\tfor i in range(len(testSet)):\n",
    "\t\tresult = predict(summaries, testSet[i])\n",
    "\t\tpredictions.append(result)\n",
    "\treturn predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener precisión\n",
    "Las predicciones se pueden comparar con los valores de clase en el conjunto de datos de prueba y la precisión de la clasificación se puede calcular como una relación de precisión entre 0 y 100%. El getAccuracy () calculará esta relación de precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "\tcorrect = 0\n",
    "\tfor x in range(len(testSet)):\n",
    "\t\tif testSet[x][-1] == predictions[x]:\n",
    "\t\t\tcorrect += 1\n",
    "\treturn (correct/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividir 768 filas en tren=514 y prueba=254 filas\n",
      "Exactitud: 73.62204724409449%\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\tfilename = 'pima-indians-diabetes.csv'\n",
    "\tsplitRatio = 0.67\n",
    "\tdataset = loadCsv()\n",
    "\ttrainingSet, testSet = splitDataset(dataset, splitRatio)\n",
    "\tprint('Dividir {0} filas en tren={1} y prueba={2} filas'.format(len(dataset), len(trainingSet), len(testSet)))\n",
    "\t# prepare model\n",
    "\tsummaries = summarizeByClass(trainingSet)\n",
    "\t# test model\n",
    "\tpredictions = getPredictions(summaries, testSet)\n",
    "\taccuracy = getAccuracy(testSet, predictions)\n",
    "\tprint('Exactitud: {0}%'.format(accuracy))\n",
    " \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
